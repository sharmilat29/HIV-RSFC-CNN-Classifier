{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "31fb6f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b685a6da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 323 files belonging to 2 classes.\n",
      "Using 162 files for training.\n",
      "Found 323 files belonging to 2 classes.\n",
      "Using 161 files for validation.\n"
     ]
    }
   ],
   "source": [
    "train_ds = keras.utils.image_dataset_from_directory(directory = 'training/', labels = 'inferred', validation_split = 0.5, subset = 'training', seed = 123)\n",
    "\n",
    "validation_ds = keras.utils.image_dataset_from_directory(directory = 'training/', labels = 'inferred', validation_split = 0.5, subset = 'validation', seed = 123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "24f3ed00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 256, 256, 3)\n",
      "(32,)\n"
     ]
    }
   ],
   "source": [
    "class_names = train_ds.class_names\n",
    "\n",
    "normalization_layer = keras.layers.Rescaling(1./255)\n",
    "\n",
    "for image_batch, labels_batch in train_ds:\n",
    "    print(image_batch.shape)\n",
    "    print(labels_batch.shape)\n",
    "    break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "81f04029",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.22248872 0.99752814\n"
     ]
    }
   ],
   "source": [
    "normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\n",
    "image_batch, labels_batch = next(iter(normalized_ds))\n",
    "first_image = image_batch[0]\n",
    "print(np.min(first_image), np.max(first_image))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "da7d3fbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_ds = train_ds.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = validation_ds.cache().prefetch(buffer_size=AUTOTUNE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "35e34da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CNN Model Building\n",
    "\n",
    "\n",
    "#num_category = 2\n",
    "#model = Sequential()\n",
    "#model.add(Conv2D(32, kernel_size = (3,3), activation = 'relu'))\n",
    "#model.add(Conv2D(64, kernel_size = (3,3), activation = 'relu'))\n",
    "#model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "#model.add(Dropout(0.25))\n",
    "#model.add(Flatten())\n",
    "# Adding a fully connected layer\n",
    "#model.add(Dense(128, activation = 'relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "#model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, kernel_size = (3,3), activation = 'relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size = (3,3), activation = 'relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size = (3,3), activation = 'relu'))\n",
    "\n",
    "model.add(MaxPooling2D(pool_size = (2,2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(512, activation = 'relu'))\n",
    "\n",
    "model.add(Dense(1, activation = 'sigmoid'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dc40c0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers\n",
    "\n",
    "model.compile (loss = keras.losses.binary_crossentropy, optimizer = optimizers.Adam(), metrics = ['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "000ce87d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "6/6 [==============================] - 5s 798ms/step - loss: 635.3762 - accuracy: 0.4877 - val_loss: 46.9405 - val_accuracy: 0.4161\n",
      "Epoch 2/15\n",
      "6/6 [==============================] - 4s 681ms/step - loss: 20.3390 - accuracy: 0.5000 - val_loss: 12.8619 - val_accuracy: 0.5839\n",
      "Epoch 3/15\n",
      "6/6 [==============================] - 5s 764ms/step - loss: 10.2451 - accuracy: 0.6111 - val_loss: 4.1479 - val_accuracy: 0.4161\n",
      "Epoch 4/15\n",
      "6/6 [==============================] - 4s 658ms/step - loss: 2.0017 - accuracy: 0.5494 - val_loss: 0.7027 - val_accuracy: 0.5404\n",
      "Epoch 5/15\n",
      "6/6 [==============================] - 4s 628ms/step - loss: 0.7435 - accuracy: 0.6296 - val_loss: 0.8692 - val_accuracy: 0.4161\n",
      "Epoch 6/15\n",
      "6/6 [==============================] - 5s 791ms/step - loss: 0.6397 - accuracy: 0.6173 - val_loss: 0.8217 - val_accuracy: 0.4161\n",
      "Epoch 7/15\n",
      "6/6 [==============================] - 4s 686ms/step - loss: 0.5818 - accuracy: 0.7160 - val_loss: 0.7050 - val_accuracy: 0.5217\n",
      "Epoch 8/15\n",
      "6/6 [==============================] - 4s 660ms/step - loss: 0.4326 - accuracy: 0.7901 - val_loss: 1.3845 - val_accuracy: 0.4161\n",
      "Epoch 9/15\n",
      "6/6 [==============================] - 4s 661ms/step - loss: 0.6370 - accuracy: 0.6296 - val_loss: 0.7070 - val_accuracy: 0.4596\n",
      "Epoch 10/15\n",
      "6/6 [==============================] - 4s 687ms/step - loss: 0.5283 - accuracy: 0.8827 - val_loss: 0.7606 - val_accuracy: 0.4224\n",
      "Epoch 11/15\n",
      "6/6 [==============================] - 4s 652ms/step - loss: 0.4870 - accuracy: 0.8148 - val_loss: 1.3479 - val_accuracy: 0.4161\n",
      "Epoch 12/15\n",
      "6/6 [==============================] - 4s 635ms/step - loss: 0.5673 - accuracy: 0.5617 - val_loss: 0.7169 - val_accuracy: 0.4658\n",
      "Epoch 13/15\n",
      "6/6 [==============================] - 4s 657ms/step - loss: 0.5023 - accuracy: 0.8704 - val_loss: 0.7366 - val_accuracy: 0.4161\n",
      "Epoch 14/15\n",
      "6/6 [==============================] - 4s 684ms/step - loss: 0.4394 - accuracy: 0.9321 - val_loss: 0.7667 - val_accuracy: 0.5839\n",
      "Epoch 15/15\n",
      "6/6 [==============================] - 4s 649ms/step - loss: 0.3203 - accuracy: 0.9136 - val_loss: 0.9698 - val_accuracy: 0.4286\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fed8c8f8b50>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_ds, validation_data=validation_ds, epochs=15, verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1e5189",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
